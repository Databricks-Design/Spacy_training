Excellent! Let me do deep research on **transaction-specific token patterns** documented in research and industry papers.Perfect! Let me compile all the research findings on **transaction-specific token patterns** from academic and industry sources.

---

## **ðŸ”¬ RESEARCH-BACKED TOKEN-LEVEL PATTERNS IN TRANSACTIONS**

Based on research papers, industry implementations, and production systems:

---

### **PATTERN 1: Positional Dominance (HIGHLY VALIDATED)**

Research shows 78.9% of merchant names appear at the beginning of transaction records, making positional features a strong hint for predicting merchants

**Token Features:**
```python
# Position-based features (VALIDATED)
position_index          # Absolute position (0, 1, 2...)
is_first_token          # Boolean: position == 0
is_second_token         # Boolean: position == 1
relative_position       # Float: position / total_tokens (0.0 to 1.0)
distance_from_end       # How far from end
```

**Why it works:** Transaction formatting standards place merchant names first for readability.

---

### **PATTERN 2: Payment Processor Prefixes (STRUCTURAL PATTERN)**

Statement descriptors follow specific patterns: payment processors use prefixes like SQ* for Square, PAYPAL* for PayPal, with formats like "PREFIX*MERCHANT*STOREID"

**Known Processor Patterns:**
```python
PROCESSOR_PATTERNS = {
    # Format: PROCESSOR*MERCHANT*OPTIONAL_ID
    'SQ': {
        'pattern': 'SQ *',
        'separator': '*',
        'structure': ['PROCESSOR', 'MERCHANT', 'LOCATION/ID']
    },
    'PAYPAL': {
        'pattern': 'PAYPAL *',
        'separator': '*', 
        'structure': ['PROCESSOR', 'MERCHANT', 'ID']
    },
    'AMZN': {
        'pattern': 'AMZ*',
        'formats': ['AMZN MKTP', 'AMZN.COM', 'AMZ*']
    },
    'GOOGLE': {
        'pattern': 'GOOGLE *',
        'variants': ['GOOGLE *PAY', 'G.CO']
    },
    'APPLE': {
        'pattern': 'APPLE.COM',
        'variants': ['APL*']
    }
}

# Token features based on this
token.is_processor_prefix     # Is it SQ, PAYPAL, etc?
token.follows_processor       # Token after processor prefix
token.processor_type          # Which processor (Square, PayPal, etc)
```

**Evidence:** Descriptor format typically includes DBA name and product/service name separated by asterisk (*), with standard length of 22 characters maximum

---

### **PATTERN 3: Separator Token Significance**

**Special Characters as Structural Markers:**
```python
SEPARATOR_TOKENS = {
    '*': 'processor_separator',    # SQ*MERCHANT*STORE
    '/': 'subdomain_separator',     # CVS/PHARMACY
    '#': 'store_id_marker',         # STORE#1234
    '-': 'compound_separator',      # WHOLE-FOODS
    '.': 'domain_separator'         # AMAZON.COM
}

# Token features
token.is_separator           # Is * / # - .
token.separator_type         # Which separator
token.before_separator       # Token immediately before separator
token.after_separator        # Token immediately after separator
```

**Pattern:** Payment processor descriptors use asterisk (*) as separator between merchant DBA name and product descriptor

---

### **PATTERN 4: Case Pattern Analysis**

Research found merchant names in transaction records are typically in uppercase, eliminating the need to solve case problems

**Token Case Features:**
```python
# Different from generic NER - transactions have specific case patterns
token.is_all_upper          # STARBUCKS (very common for merchants)
token.is_mixed_case         # StArBuCkS (rare, likely error)
token.is_title_case         # Starbucks (less common)
token.has_internal_caps     # StarBucks (brand-specific)
token.case_consistency      # All tokens in entity have same case?

# Transaction-specific patterns
token.is_merchant_case      # ALL UPPER or TitleCase only
token.is_location_case      # Usually TitleCase or lowercase (CA, ny)
token.is_code_case          # UPPER + digits (ABC123)
```

---

### **PATTERN 5: Token Composition Patterns**

**Alphanumeric Structure:**
```python
# Store/Location IDs
STORE_ID_PATTERNS = {
    'hash_numeric': r'#\d+',           # #1234
    'store_numeric': r'STORE\s*\d+',   # STORE 456, STORE456
    'loc_numeric': r'LOC\s*\d+',       # LOC 123
    'number_only': r'^\d{4,5}$'        # 12345 (zip or store)
}

# Token features
token.is_store_id           # Matches store ID pattern
token.has_leading_hash      # Starts with #
token.digit_count           # Number of digits
token.alpha_count           # Number of letters
token.digit_ratio           # digits / total_length
token.alpha_digit_pattern   # ABC123, 123ABC, AB12CD
```

**Industry Pattern:** Store numbers are typically 3-5 digits, zip codes are 5 digits.

---

### **PATTERN 6: Abbreviation Detection**

**Transaction-Specific Abbreviations:**
```python
# Common merchant abbreviations
MERCHANT_ABBREVIATIONS = {
    'short_caps': {
        'pattern': r'^[A-Z]{2,5}$',
        'examples': ['CVS', 'TGT', 'WMT', 'HD'],
        'length': 2-5
    },
    'vowel_dropped': {
        'pattern': r'^[B-DF-HJ-NP-TV-Z]{3,6}$',  # Mostly consonants
        'examples': ['STRBKS', 'WLMRT', 'TRGT'],
        'vowel_ratio': '<30%'
    },
    'compressed': {
        'pattern': r'^[A-Z]+\d*[A-Z]*$',
        'examples': ['AMZN', 'MKTP', 'PYMT']
    }
}

# Token features
token.is_abbreviation          # Matches abbreviation pattern
token.vowel_ratio              # vowels / total_chars
token.consonant_ratio          # consonants / total_chars
token.compression_score        # How "compressed" (few vowels)
token.likely_full_word         # Has normal vowel distribution
```

---

### **PATTERN 7: Location/Address Indicators**

**Geographic Token Patterns:**
```python
LOCATION_PATTERNS = {
    'state_codes': ['AL', 'AK', 'AZ', 'CA', 'NY', 'TX', ...],  # US states
    'street_types': ['ST', 'AVE', 'BLVD', 'RD', 'LN', 'DR', 'CT'],
    'direction': ['N', 'S', 'E', 'W', 'NE', 'NW', 'SE', 'SW'],
    'zip_codes': r'\d{5}(-\d{4})?',
    'countries': ['US', 'USA', 'UK', 'CA', 'IN']
}

# Token features
token.is_state_code           # 2-letter state
token.is_street_type          # ST, AVE, etc.
token.is_direction            # N, S, E, W
token.is_zip_code             # 5 digits
token.is_country_code         # US, UK, etc.
token.location_indicator      # Any of above
```

---

### **PATTERN 8: Transaction Type Keywords**

**Non-Entity Keywords (Important Negatives):**
```python
TRANSACTION_KEYWORDS = {
    'transaction_type': ['DEBIT', 'CREDIT', 'PAYMENT', 'PURCHASE', 'WITHDRAWAL', 'DEPOSIT', 'TRANSFER'],
    'descriptors': ['PENDING', 'AUTHORIZED', 'SETTLED', 'REFUND', 'REVERSAL'],
    'temporal': ['TODAY', 'YESTERDAY', 'RECURRING', 'AUTO'],
    'amounts': ['AMOUNT', 'TOTAL', 'BALANCE', 'FEE', 'CHARGE']
}

# Token features
token.is_transaction_keyword   # Unlikely to be merchant/entity
token.keyword_category          # Which category
token.is_noise_word            # Should be filtered out
```

**Pattern:** These keywords are common but rarely part of the actual entity.

---

### **PATTERN 9: Frequency-Based Features**

Frequency analysis shows bank names are more frequent than merchant names; merchants may be frequent in one subset but rare in others

```python
# Extract from YOUR training data
FREQUENCY_FEATURES = {
    'global_frequency': {},      # How often token appears in corpus
    'entity_frequency': {},      # How often it appears IN entities
    'non_entity_frequency': {}   # How often OUTSIDE entities
}

# Token features
token.corpus_frequency          # Overall frequency
token.entity_likelihood         # P(entity | token appears)
token.is_common_word            # High frequency, low entity rate
token.is_rare_token             # Low frequency (could be specific merchant)
token.frequency_ratio           # entity_freq / total_freq
```

---

### **PATTERN 10: Context Window Patterns**

**Bigram/Trigram Patterns:**
```python
# Common patterns found in research
CONTEXT_PATTERNS = {
    'processor_merchant': {
        'bigrams': [('SQ', '*'), ('PAYPAL', '*'), ('AMZN', 'MKTP')],
        'indicates': 'processor prefix'
    },
    'merchant_location': {
        'bigrams': [('MERCHANT', 'NY'), ('MERCHANT', 'CA'), ('MERCHANT', 'US')],
        'indicates': 'merchant followed by location'
    },
    'merchant_store': {
        'bigrams': [('MERCHANT', '#'), ('MERCHANT', 'STORE'), ('MERCHANT', 'NO')],
        'indicates': 'merchant followed by store ID'
    }
}

# Token features
token.bigram_with_prev         # Current + previous token
token.bigram_with_next         # Current + next token
token.trigram_context          # Prev + current + next
token.context_pattern_type     # Which pattern matches
```

---

### **PATTERN 11: Numeric Token Semantics**

**Numeric patterns have specific meanings:**
```python
NUMERIC_PATTERNS = {
    'store_number': {
        'pattern': r'^\d{3,5}$',
        'position': 'after merchant',
        'preceded_by': ['#', 'STORE', 'NO', 'LOC']
    },
    'zip_code': {
        'pattern': r'^\d{5}$',
        'position': 'end of text',
        'preceded_by': state_codes
    },
    'transaction_id': {
        'pattern': r'^\d{6,}$',
        'context': 'isolated, not near merchant'
    },
    'phone_suffix': {
        'pattern': r'^\d{4}$',
        'preceded_by': area_code_or_prefix
    }
}

# Token features
token.numeric_type             # store/zip/txn/phone
token.numeric_length           # 3, 4, 5, 6+ digits
token.numeric_context          # What precedes it
token.likely_entity_part       # Store ID vs transaction ID
```

---

### **PATTERN 12: Domain/Web Patterns**

```python
DOMAIN_PATTERNS = {
    'full_domain': r'([a-z0-9-]+\.)+[a-z]{2,}',   # amazon.com
    'subdomain': r'[a-z0-9-]+\.[a-z0-9-]+',       # aws.amazon
    'path_like': r'[a-z]+/[a-z]+',                # amzn/mktp
    'email_like': r'[a-z0-9]+@[a-z0-9]+',         # upi@paytm
}

# Token features
token.is_domain                # Contains .com, .net, etc.
token.has_dot_separator        # Contains .
token.is_url_like              # Looks like domain/URL
token.domain_tld               # .com, .org, .in
```

---

## **ðŸ“Š RESEARCH SYNTHESIS: FEATURE IMPORTANCE HIERARCHY**

Based on all research:

### **Tier S: Critical (Proven Impact)**
1. **Position (first 2-3 tokens)** - 78.9% of merchants start here
2. **Processor prefix detection** - Structural indicator
3. **Case patterns (ALL UPPER)** - Strong merchant signal
4. **Separator tokens (*)** - Structural boundaries

### **Tier A: High Value**
5. **Abbreviation detection** - Common in transactions
6. **Store ID patterns** - Helps separate merchant from metadata
7. **Alphanumeric composition** - Distinguishes entity types
8. **Location indicators** - Helps identify entity boundaries

### **Tier B: Moderate Value**
9. **Frequency features** - Distinguish common vs specific
10. **Context bigrams** - Pattern recognition
11. **Transaction keywords** - Negative indicators
12. **Numeric semantics** - Type classification

---

## **ðŸ’¡ FINAL FEATURE RECOMMENDATION FOR YOUR CASE**

```python
# Implement these token-level features
class TransactionTokenFeatures:
    """
    Research-backed token features for transaction NER
    """
    
    # TIER S - Must have
    position_index: int              # Absolute position
    is_first_three: bool             # In first 3 tokens (78.9% rule)
    is_all_upper: bool               # ALL CAPS (merchant pattern)
    processor_prefix: Optional[str]   # SQ, PAYPAL, AMZN, etc.
    has_separator: bool              # Contains * / # -
    
    # TIER A - High value
    is_abbreviation: bool            # Short, consonant-heavy
    vowel_ratio: float               # Vowels / total_chars
    is_store_id: bool                # #1234, STORE123 pattern
    alpha_digit_pattern: str         # ABC, 123, ABC123, etc.
    is_location_indicator: bool      # ST, CA, US, ZIP
    
    # TIER B - Nice to have
    token_frequency: float           # From training corpus
    follows_processor: bool          # Token after SQ*, PAYPAL*
    is_transaction_keyword: bool     # DEBIT, PAYMENT, etc.
    numeric_type: Optional[str]      # store/zip/txn/phone
```

Want me to show you the implementation code for these validated patterns?
